{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CT-PINN-DADif: Physics-Informed Deep Adaptive Diffusion Network for CT Reconstruction\n",
        "\n",
        "This notebook provides a complete training pipeline for CT-PINN-DADif, adapted from the MRI PINN-DADif paper (Ahmed et al., 2025) for CT reconstruction.\n",
        "\n",
        "## Key Differences from MRI Version:\n",
        "- **Physics**: Radon Transform / Sinogram instead of Fourier / k-space\n",
        "- **Noise Model**: Poisson photon counting instead of Gaussian\n",
        "- **Data Consistency**: Sinogram consistency instead of k-space consistency\n",
        "- **Regularization**: Total Variation + Non-negativity instead of Bloch equations\n",
        "\n",
        "## Architecture Overview:\n",
        "1. **CT-LPCE**: Encodes sinogram to latent features with physics constraints\n",
        "2. **CT-PACE**: Multi-scale context encoding with ASPP and attention\n",
        "3. **CT-ADRN**: Adaptive diffusion refinement with sinogram consistency\n",
        "4. **CT-ART**: Final synthesis with dynamic convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository (if running on Colab)\n",
        "!git clone https://github.com/Iammohithhh/PINN_Dadiff.git\n",
        "%cd PINN_Dadiff/ct_reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision numpy scipy tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'src')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "if device == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import CT-PINN-DADif Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ct_physics import (\n",
        "    RadonTransform, FilteredBackProjection, CTForwardModel,\n",
        "    create_sparse_view_mask, create_limited_angle_mask\n",
        ")\n",
        "from model import CT_PINN_DADif, CTReconstructionLoss, SAM, create_model, create_loss\n",
        "from data_loader import SimulatedCTDataset, create_dataloaders, create_shepp_logan_phantom\n",
        "from train import Trainer, compute_metrics, DEFAULT_CONFIG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Visualize CT Physics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a Shepp-Logan phantom\n",
        "phantom = create_shepp_logan_phantom(256)\n",
        "\n",
        "# Convert to tensor\n",
        "phantom_tensor = torch.from_numpy(phantom).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "\n",
        "# Create forward model\n",
        "ct_model = CTForwardModel(img_size=256, num_angles=180, I0=1e4, device=device)\n",
        "\n",
        "# Generate sinogram\n",
        "sinogram_clean = ct_model.forward_project(phantom_tensor)\n",
        "sinogram_noisy, counts = ct_model(phantom_tensor, add_noise=True, return_counts=True)\n",
        "\n",
        "# FBP reconstruction\n",
        "fbp = FilteredBackProjection(256, 180, device=device)\n",
        "fbp_recon = fbp(sinogram_noisy)\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "axes[0, 0].imshow(phantom, cmap='gray')\n",
        "axes[0, 0].set_title('Ground Truth Phantom')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(sinogram_clean.squeeze().cpu().numpy(), cmap='gray', aspect='auto')\n",
        "axes[0, 1].set_title('Clean Sinogram')\n",
        "axes[0, 1].set_xlabel('Detector')\n",
        "axes[0, 1].set_ylabel('Angle')\n",
        "\n",
        "axes[0, 2].imshow(sinogram_noisy.squeeze().cpu().numpy(), cmap='gray', aspect='auto')\n",
        "axes[0, 2].set_title('Noisy Sinogram (Poisson)')\n",
        "axes[0, 2].set_xlabel('Detector')\n",
        "axes[0, 2].set_ylabel('Angle')\n",
        "\n",
        "axes[1, 0].imshow(fbp_recon.squeeze().cpu().numpy(), cmap='gray')\n",
        "axes[1, 0].set_title('FBP Reconstruction')\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "# Sparse-view simulation\n",
        "sparse_mask = create_sparse_view_mask(180, 30, device)\n",
        "sinogram_sparse = sinogram_noisy * sparse_mask\n",
        "fbp_sparse = fbp(sinogram_sparse)\n",
        "\n",
        "axes[1, 1].imshow(sinogram_sparse.squeeze().cpu().numpy(), cmap='gray', aspect='auto')\n",
        "axes[1, 1].set_title('Sparse-View Sinogram (30 views)')\n",
        "\n",
        "axes[1, 2].imshow(fbp_sparse.squeeze().cpu().numpy(), cmap='gray')\n",
        "axes[1, 2].set_title('FBP from Sparse-View')\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('ct_physics_demo.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# Compute metrics\n",
        "metrics_fbp = compute_metrics(fbp_recon, phantom_tensor)\n",
        "print(f\"\\nFBP Reconstruction Metrics:\")\n",
        "print(f\"  PSNR: {metrics_fbp['psnr']:.2f} dB\")\n",
        "print(f\"  SSIM: {metrics_fbp['ssim']:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Configure Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "config = {\n",
        "    # Model architecture\n",
        "    'img_size': 256,\n",
        "    'num_angles': 180,\n",
        "    'num_detectors': None,  # Auto-compute\n",
        "    'base_channels': 64,\n",
        "    'latent_dim': 128,\n",
        "    'context_dim': 256,\n",
        "    'num_diffusion_steps': 12,\n",
        "    'lambda_phys_lpce': 0.3,\n",
        "    'lambda_phys_pace': 0.1,\n",
        "    'use_final_dc': True,\n",
        "    \n",
        "    # Dataset\n",
        "    'dataset_type': 'simulated',\n",
        "    'num_train_samples': 500,   # Reduce for Colab\n",
        "    'num_val_samples': 100,\n",
        "    'num_test_samples': 100,\n",
        "    'phantom_type': 'mixed',    # 'shepp_logan', 'random', 'mixed'\n",
        "    'noise_level': 'low',       # 'none', 'low', 'medium', 'high'\n",
        "    'acquisition_type': 'full', # 'full', 'sparse', 'limited'\n",
        "    'num_views': 60,            # For sparse-view\n",
        "    \n",
        "    # Training\n",
        "    'batch_size': 2,            # Reduce for Colab GPU memory\n",
        "    'num_epochs': 100,          # Reduce for demo\n",
        "    'learning_rate': 6e-3,\n",
        "    'use_sam': True,            # Sharpness-Aware Minimization\n",
        "    'sam_rho': 0.05,\n",
        "    'use_amp': True,            # Mixed precision\n",
        "    'num_workers': 2,\n",
        "    \n",
        "    # Loss weights\n",
        "    'alpha': 0.5,               # Pixel loss\n",
        "    'beta': 0.2,                # Perceptual loss\n",
        "    'gamma': 0.3,               # Physics loss\n",
        "    'tv_weight': 1e-4,\n",
        "    'nonneg_weight': 1e-3,\n",
        "    'use_poisson': False,\n",
        "    'use_perceptual': False,    # Disable for faster training\n",
        "    \n",
        "    # Checkpointing\n",
        "    'checkpoint_dir': 'experiments/checkpoints',\n",
        "    'log_dir': 'experiments/logs',\n",
        "    'save_every': 25\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for k, v in config.items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Model and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataloaders\n",
        "print(\"Creating datasets...\")\n",
        "train_loader, val_loader, test_loader = create_dataloaders(\n",
        "    config,\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers']\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Visualize a sample\n",
        "sample = next(iter(train_loader))\n",
        "print(f\"\\nSample shapes:\")\n",
        "for k, v in sample.items():\n",
        "    if isinstance(v, torch.Tensor):\n",
        "        print(f\"  {k}: {v.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "print(\"Creating CT-PINN-DADif model...\")\n",
        "model = create_model(config)\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Create loss function\n",
        "loss_fn = create_loss(config)\n",
        "loss_fn = loss_fn.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test forward pass\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    sinogram = sample['sinogram_noisy'].to(device)\n",
        "    target = sample['image'].to(device)\n",
        "    weights = sample['weights'].to(device)\n",
        "    mask = sample['mask'].to(device)\n",
        "    \n",
        "    print(f\"Input sinogram: {sinogram.shape}\")\n",
        "    \n",
        "    # Forward pass\n",
        "    outputs = model(sinogram, weights, mask, return_intermediate=True)\n",
        "    \n",
        "    print(f\"\\nOutput shapes:\")\n",
        "    for k, v in outputs.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            print(f\"  {k}: {v.shape}\")\n",
        "    \n",
        "    # Compute metrics\n",
        "    metrics = compute_metrics(outputs['reconstruction'], target)\n",
        "    print(f\"\\nInitial metrics (before training):\")\n",
        "    print(f\"  PSNR: {metrics['psnr']:.2f} dB\")\n",
        "    print(f\"  SSIM: {metrics['ssim']:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    config=config,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Train!\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "history = trainer.train(\n",
        "    num_epochs=config['num_epochs'],\n",
        "    start_epoch=0\n",
        ")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Training complete!\")\n",
        "print(f\"Best PSNR: {trainer.best_psnr:.2f} dB\")\n",
        "print(f\"Best SSIM: {trainer.best_ssim:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualize Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(history['train_loss'], label='Train')\n",
        "axes[0].plot(history['val_loss'], label='Val')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# PSNR\n",
        "axes[1].plot(history['train_psnr'], label='Train')\n",
        "axes[1].plot(history['val_psnr'], label='Val')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('PSNR (dB)')\n",
        "axes[1].set_title('PSNR')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "# SSIM\n",
        "axes[2].plot(history['train_ssim'], label='Train')\n",
        "axes[2].plot(history['val_ssim'], label='Val')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('SSIM (%)')\n",
        "axes[2].set_title('SSIM')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "checkpoint = torch.load('experiments/checkpoints/best_model.pt', map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Evaluate on test set\n",
        "test_psnr = []\n",
        "test_ssim = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc='Testing'):\n",
        "        sinogram = batch['sinogram_noisy'].to(device)\n",
        "        target = batch['image'].to(device)\n",
        "        weights = batch['weights'].to(device)\n",
        "        mask = batch['mask'].to(device)\n",
        "        \n",
        "        outputs = model(sinogram, weights, mask)\n",
        "        metrics = compute_metrics(outputs['reconstruction'], target)\n",
        "        \n",
        "        test_psnr.append(metrics['psnr'])\n",
        "        test_ssim.append(metrics['ssim'])\n",
        "\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"  PSNR: {np.mean(test_psnr):.2f} +/- {np.std(test_psnr):.2f} dB\")\n",
        "print(f\"  SSIM: {np.mean(test_ssim):.2f} +/- {np.std(test_ssim):.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Visualize Reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a few test samples\n",
        "model.eval()\n",
        "test_batch = next(iter(test_loader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    sinogram = test_batch['sinogram_noisy'].to(device)\n",
        "    target = test_batch['image'].to(device)\n",
        "    weights = test_batch['weights'].to(device)\n",
        "    mask = test_batch['mask'].to(device)\n",
        "    fbp_recon = test_batch['fbp'].to(device)\n",
        "    \n",
        "    outputs = model(sinogram, weights, mask)\n",
        "\n",
        "# Visualize\n",
        "n_samples = min(4, sinogram.shape[0])\n",
        "fig, axes = plt.subplots(n_samples, 4, figsize=(16, 4*n_samples))\n",
        "\n",
        "for i in range(n_samples):\n",
        "    # Ground truth\n",
        "    axes[i, 0].imshow(target[i, 0].cpu().numpy(), cmap='gray')\n",
        "    axes[i, 0].set_title('Ground Truth')\n",
        "    axes[i, 0].axis('off')\n",
        "    \n",
        "    # FBP\n",
        "    fbp_metrics = compute_metrics(fbp_recon[i:i+1], target[i:i+1])\n",
        "    axes[i, 1].imshow(fbp_recon[i, 0].cpu().numpy(), cmap='gray')\n",
        "    axes[i, 1].set_title(f'FBP (PSNR: {fbp_metrics[\"psnr\"]:.1f})')\n",
        "    axes[i, 1].axis('off')\n",
        "    \n",
        "    # CT-PINN-DADif\n",
        "    rec = outputs['reconstruction']\n",
        "    rec_metrics = compute_metrics(rec[i:i+1], target[i:i+1])\n",
        "    axes[i, 2].imshow(rec[i, 0].cpu().numpy(), cmap='gray')\n",
        "    axes[i, 2].set_title(f'CT-PINN-DADif (PSNR: {rec_metrics[\"psnr\"]:.1f})')\n",
        "    axes[i, 2].axis('off')\n",
        "    \n",
        "    # Error map\n",
        "    error = torch.abs(rec[i, 0] - target[i, 0]).cpu().numpy()\n",
        "    axes[i, 3].imshow(error, cmap='hot', vmin=0, vmax=0.1)\n",
        "    axes[i, 3].set_title('Error Map')\n",
        "    axes[i, 3].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('reconstructions.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Save Model for Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model for deployment\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'config': config\n",
        "}, 'ct_pinn_dadif_final.pt')\n",
        "\n",
        "print(\"Model saved to ct_pinn_dadif_final.pt\")\n",
        "\n",
        "# Download from Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('ct_pinn_dadif_final.pt')\n",
        "except:\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
